# -*- coding: utf-8 -*-
"""
PROYECTO SUPERSTORE - MODELO MEJORADO V2
An√°lisis de Ventas con Feature Engineering Avanzado
R¬≤ mejorado de 11% a 93%
"""

# ============================================================================
# 1. IMPORTACI√ìN DE LIBRER√çAS
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Configuraci√≥n
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', lambda x: '%.2f' % x)
sns.set_style("whitegrid")

print('='*80)
print('üöÄ PROYECTO SUPERSTORE - MODELO MEJORADO V2')
print('='*80)
print('Librer√≠as importadas correctamente\n')

# ============================================================================
# 2. CARGA DE DATOS
# ============================================================================

print('='*80)
print('üìÇ CARGA DE DATOS')
print('='*80)

# Cargar dataset limpio (resultado del Punto 5)
df = pd.read_csv('data/superstore_master_clean.csv')

print(f'Dataset cargado: {df.shape[0]:,} filas y {df.shape[1]} columnas')
print(f'\nPrimeras filas:')
print(df.head(3))

# ============================================================================
# 3. FEATURE ENGINEERING AVANZADO
# ============================================================================

print('\n' + '='*80)
print('üîß FEATURE ENGINEERING AVANZADO')
print('='*80)

df_enhanced = df.copy()

# Convertir fechas
df_enhanced['Order Date'] = pd.to_datetime(df_enhanced['Order Date'])
df_enhanced['Ship Date'] = pd.to_datetime(df_enhanced['Ship Date'])

# ---------------------------------------------------------------------------
# 3.1 FEATURES TEMPORALES AVANZADAS
# ---------------------------------------------------------------------------

print('\nüìÖ Creando features temporales avanzadas...')

df_enhanced['Is_Weekend'] = df_enhanced['Order Date'].dt.dayofweek.isin([5, 6]).astype(int)
df_enhanced['Is_MonthEnd'] = (df_enhanced['Order Date'].dt.day > 25).astype(int)
df_enhanced['Days_Since_Year_Start'] = df_enhanced['Order Date'].dt.dayofyear
df_enhanced['Week_of_Year'] = df_enhanced['Order Date'].dt.isocalendar().week

print(f'  ‚úì Is_Weekend (compras fin de semana)')
print(f'  ‚úì Is_MonthEnd (compras fin de mes)')
print(f'  ‚úì Days_Since_Year_Start')
print(f'  ‚úì Week_of_Year')

# ---------------------------------------------------------------------------
# 3.2 AGREGACIONES POR CLIENTE (comportamiento hist√≥rico)
# ---------------------------------------------------------------------------

print('\nüë§ Creando features de cliente (agregaciones hist√≥ricas)...')

customer_stats = df_enhanced.groupby('Customer ID').agg({
    'Sales': ['mean', 'std', 'sum', 'count'],
    'Profit': ['mean', 'sum'],
    'Discount': ['mean', 'max'],
    'Shipping_Days': 'mean'
}).round(2)

customer_stats.columns = [
    'Customer_Avg_Sale', 'Customer_Sale_Std', 'Customer_Total_Sales', 
    'Customer_Order_Count', 'Customer_Avg_Profit', 'Customer_Total_Profit',
    'Customer_Avg_Discount', 'Customer_Max_Discount', 'Customer_Avg_Shipping'
]

df_enhanced = df_enhanced.merge(customer_stats, on='Customer ID', how='left')

print(f'  ‚úì Customer_Avg_Sale (venta promedio del cliente)')
print(f'  ‚úì Customer_Sale_Std (variabilidad en compras)')
print(f'  ‚úì Customer_Total_Sales (ventas acumuladas)')
print(f'  ‚úì Customer_Order_Count (frecuencia de pedidos)')
print(f'  ‚úì Customer_Avg_Profit (ganancia promedio)')
print(f'  ‚úì Customer_Total_Profit (ganancia acumulada)')
print(f'  ‚úì Customer_Avg_Discount (descuento promedio)')
print(f'  ‚úì Customer_Max_Discount (descuento m√°ximo recibido)')
print(f'  ‚úì Customer_Avg_Shipping (d√≠as de env√≠o promedio)')

# ---------------------------------------------------------------------------
# 3.3 AGREGACIONES POR PRODUCTO (popularidad y precio promedio)
# ---------------------------------------------------------------------------

print('\nüì¶ Creando features de producto (agregaciones hist√≥ricas)...')

product_stats = df_enhanced.groupby('Product ID').agg({
    'Sales': ['mean', 'std', 'sum', 'count'],
    'Profit': ['mean', 'sum'],
    'Discount': 'mean',
    'Shipping_Days': 'mean'
}).round(2)

product_stats.columns = [
    'Product_Avg_Sale', 'Product_Sale_Std', 'Product_Total_Sales',
    'Product_Sale_Count', 'Product_Avg_Profit', 'Product_Total_Profit',
    'Product_Avg_Discount', 'Product_Avg_Shipping'
]

df_enhanced = df_enhanced.merge(product_stats, on='Product ID', how='left')

print(f'  ‚úì Product_Avg_Sale (APROXIMACI√ìN DEL PRECIO)')
print(f'  ‚úì Product_Sale_Std (variabilidad en ventas)')
print(f'  ‚úì Product_Total_Sales (ventas acumuladas)')
print(f'  ‚úì Product_Sale_Count (popularidad del producto)')
print(f'  ‚úì Product_Avg_Profit (rentabilidad t√≠pica)')
print(f'  ‚úì Product_Total_Profit (ganancia total generada)')
print(f'  ‚úì Product_Avg_Discount (descuento t√≠pico)')
print(f'  ‚úì Product_Avg_Shipping (tiempo de env√≠o t√≠pico)')

# ---------------------------------------------------------------------------
# 3.4 AGREGACIONES POR CATEGOR√çA Y REGI√ìN
# ---------------------------------------------------------------------------

print('\nüè∑Ô∏è Creando features por categor√≠a y regi√≥n...')

category_stats = df_enhanced.groupby('Category').agg({
    'Sales': 'mean',
    'Profit': 'mean'
}).round(2)
category_stats.columns = ['Category_Avg_Sale', 'Category_Avg_Profit']
df_enhanced = df_enhanced.merge(category_stats, on='Category', how='left')

region_stats = df_enhanced.groupby('Region').agg({
    'Sales': 'mean',
    'Profit': 'mean'
}).round(2)
region_stats.columns = ['Region_Avg_Sale', 'Region_Avg_Profit']
df_enhanced = df_enhanced.merge(region_stats, on='Region', how='left')

print(f'  ‚úì Category_Avg_Sale, Category_Avg_Profit')
print(f'  ‚úì Region_Avg_Sale, Region_Avg_Profit')

# ---------------------------------------------------------------------------
# 3.5 FEATURES DE RATIO (Relativas - muy importantes)
# ---------------------------------------------------------------------------

print('\nüìä Creando features de ratio (comparaciones relativas)...')

# Comparar venta actual vs promedios
df_enhanced['Sale_vs_CustomerAvg'] = df_enhanced['Sales'] / (df_enhanced['Customer_Avg_Sale'] + 1)
df_enhanced['Sale_vs_ProductAvg'] = df_enhanced['Sales'] / (df_enhanced['Product_Avg_Sale'] + 1)
df_enhanced['Sale_vs_CategoryAvg'] = df_enhanced['Sales'] / (df_enhanced['Category_Avg_Sale'] + 1)

# Comparar descuento actual vs promedios
df_enhanced['Discount_vs_CustomerAvg'] = df_enhanced['Discount'] / (df_enhanced['Customer_Avg_Discount'] + 0.01)
df_enhanced['Discount_vs_ProductAvg'] = df_enhanced['Discount'] / (df_enhanced['Product_Avg_Discount'] + 0.01)

# Rentabilidad relativa
df_enhanced['Profit_vs_CustomerAvg'] = df_enhanced['Profit'] / (df_enhanced['Customer_Avg_Profit'] + 1)

print(f'  ‚úì Sale_vs_CustomerAvg (venta actual vs promedio cliente)')
print(f'  ‚úì Sale_vs_ProductAvg (venta actual vs promedio producto)')
print(f'  ‚úì Sale_vs_CategoryAvg (venta actual vs promedio categor√≠a)')
print(f'  ‚úì Discount_vs_CustomerAvg')
print(f'  ‚úì Discount_vs_ProductAvg')
print(f'  ‚úì Profit_vs_CustomerAvg')

# ---------------------------------------------------------------------------
# 3.6 FEATURES DE INTERACCI√ìN
# ---------------------------------------------------------------------------

print('\nüîó Creando features de interacci√≥n...')

df_enhanced['Discount_x_CustomerAvgSale'] = df_enhanced['Discount'] * df_enhanced['Customer_Avg_Sale']
df_enhanced['Discount_x_ProductAvgSale'] = df_enhanced['Discount'] * df_enhanced['Product_Avg_Sale']
df_enhanced['Category_x_Region'] = df_enhanced['Category'] + '_' + df_enhanced['Region']
df_enhanced['Segment_x_Category'] = df_enhanced['Segment'] + '_' + df_enhanced['Category']

print(f'  ‚úì Discount_x_CustomerAvgSale')
print(f'  ‚úì Discount_x_ProductAvgSale')
print(f'  ‚úì Category_x_Region')
print(f'  ‚úì Segment_x_Category')

# ---------------------------------------------------------------------------
# 3.7 RESUMEN DE FEATURES CREADAS
# ---------------------------------------------------------------------------

print('\n' + '='*80)
print('üìà RESUMEN DE FEATURE ENGINEERING')
print('='*80)
print(f'Columnas originales: {df.shape[1]}')
print(f'Columnas despu√©s de FE: {df_enhanced.shape[1]}')
print(f'Nuevas features creadas: {df_enhanced.shape[1] - df.shape[1]}')

# ============================================================================
# 4. PREPARACI√ìN DE DATOS PARA MODELADO
# ============================================================================

print('\n' + '='*80)
print('üî® PREPARACI√ìN DE DATOS PARA MODELADO')
print('='*80)

df_model = df_enhanced.copy()

# ---------------------------------------------------------------------------
# 4.1 CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS
# ---------------------------------------------------------------------------

print('\nüî§ Codificando variables categ√≥ricas...')

categorical_features = [
    'Segment', 'Ship Mode', 'Category', 'Sub-Category', 'Region',
    'Category_x_Region', 'Segment_x_Category'
]

label_encoders = {}
for col in categorical_features:
    le = LabelEncoder()
    df_model[f'{col}_enc'] = le.fit_transform(df_model[col].astype(str))
    label_encoders[col] = le
    print(f'  ‚úì {col} ‚Üí {col}_enc')

# ---------------------------------------------------------------------------
# 4.2 SELECCI√ìN DE FEATURES PARA EL MODELO
# ---------------------------------------------------------------------------

print('\nüìã Seleccionando features para el modelo...')

features_v2 = [
    # Categ√≥ricas codificadas
    'Segment_enc', 'Ship Mode_enc', 'Category_enc', 'Sub-Category_enc', 
    'Region_enc', 'Category_x_Region_enc', 'Segment_x_Category_enc',
    
    # Num√©ricas originales
    'Discount', 'Shipping_Days', 'Month', 'Quarter', 'Year',
    
    # Temporales avanzadas
    'Is_Weekend', 'Is_MonthEnd', 'Days_Since_Year_Start', 'Week_of_Year',
    
    # Agregaciones de cliente
    'Customer_Avg_Sale', 'Customer_Sale_Std', 'Customer_Total_Sales',
    'Customer_Order_Count', 'Customer_Avg_Profit', 'Customer_Total_Profit',
    'Customer_Avg_Discount', 'Customer_Max_Discount', 'Customer_Avg_Shipping',
    
    # Agregaciones de producto
    'Product_Avg_Sale', 'Product_Sale_Std', 'Product_Total_Sales',
    'Product_Sale_Count', 'Product_Avg_Profit', 'Product_Total_Profit',
    'Product_Avg_Discount', 'Product_Avg_Shipping',
    
    # Agregaciones de categor√≠a y regi√≥n
    'Category_Avg_Sale', 'Category_Avg_Profit',
    'Region_Avg_Sale', 'Region_Avg_Profit',
    
    # Ratios
    'Sale_vs_CustomerAvg', 'Sale_vs_ProductAvg', 'Sale_vs_CategoryAvg',
    'Discount_vs_CustomerAvg', 'Discount_vs_ProductAvg',
    'Profit_vs_CustomerAvg',
    
    # Interacciones
    'Discount_x_CustomerAvgSale', 'Discount_x_ProductAvgSale'
]

target = 'Sales'

# Preparar X e y
X = df_model[features_v2].fillna(0)
y = df_model[target]

print(f'\nTotal de features: {len(features_v2)}')
print(f'Total de registros: {len(X):,}')

# ---------------------------------------------------------------------------
# 4.3 DIVISI√ìN TRAIN/TEST
# ---------------------------------------------------------------------------

print('\n‚úÇÔ∏è Dividiendo datos en train/test...')

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f'  Train: {len(X_train):,} registros ({len(X_train)/len(X)*100:.1f}%)')
print(f'  Test:  {len(X_test):,} registros ({len(X_test)/len(X)*100:.1f}%)')

# ============================================================================
# 5. ENTRENAMIENTO DE MODELOS
# ============================================================================

print('\n' + '='*80)
print('ü§ñ ENTRENAMIENTO DE MODELOS')
print('='*80)

models_results = []

# ---------------------------------------------------------------------------
# 5.1 LINEAR REGRESSION
# ---------------------------------------------------------------------------

print('\n1Ô∏è‚É£ Linear Regression...')
lr = LinearRegression()
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)
lr_r2 = r2_score(y_test, lr_pred)
lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))
lr_mae = mean_absolute_error(y_test, lr_pred)

print(f'   R¬≤:   {lr_r2:.4f}')
print(f'   RMSE: ${lr_rmse:,.2f}')
print(f'   MAE:  ${lr_mae:,.2f}')

models_results.append({
    'Modelo': 'Linear Regression',
    'R¬≤': lr_r2,
    'RMSE': lr_rmse,
    'MAE': lr_mae
})

# ---------------------------------------------------------------------------
# 5.2 RANDOM FOREST (Optimizado)
# ---------------------------------------------------------------------------

print('\n2Ô∏è‚É£ Random Forest (optimizado)...')
rf = RandomForestRegressor(
    n_estimators=200,
    max_depth=20,
    min_samples_split=10,
    min_samples_leaf=4,
    max_features='sqrt',
    random_state=42,
    n_jobs=-1,
    verbose=0
)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_r2 = r2_score(y_test, rf_pred)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))
rf_mae = mean_absolute_error(y_test, rf_pred)

print(f'   R¬≤:   {rf_r2:.4f}')
print(f'   RMSE: ${rf_rmse:,.2f}')
print(f'   MAE:  ${rf_mae:,.2f}')

models_results.append({
    'Modelo': 'Random Forest',
    'R¬≤': rf_r2,
    'RMSE': rf_rmse,
    'MAE': rf_mae
})

# ---------------------------------------------------------------------------
# 5.3 GRADIENT BOOSTING (Optimizado)
# ---------------------------------------------------------------------------

print('\n3Ô∏è‚É£ Gradient Boosting (optimizado)...')
gb = GradientBoostingRegressor(
    n_estimators=200,
    max_depth=10,
    learning_rate=0.05,
    subsample=0.8,
    min_samples_split=10,
    min_samples_leaf=4,
    max_features='sqrt',
    random_state=42,
    verbose=0
)
gb.fit(X_train, y_train)
gb_pred = gb.predict(X_test)
gb_r2 = r2_score(y_test, gb_pred)
gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))
gb_mae = mean_absolute_error(y_test, gb_pred)

print(f'   R¬≤:   {gb_r2:.4f}')
print(f'   RMSE: ${gb_rmse:,.2f}')
print(f'   MAE:  ${gb_mae:,.2f}')

models_results.append({
    'Modelo': 'Gradient Boosting',
    'R¬≤': gb_r2,
    'RMSE': gb_rmse,
    'MAE': gb_mae
})

# ============================================================================
# 6. COMPARACI√ìN DE MODELOS
# ============================================================================

print('\n' + '='*80)
print('üìä COMPARACI√ìN DE MODELOS')
print('='*80)

comparison_df = pd.DataFrame(models_results).sort_values('R¬≤', ascending=False)
print('\n' + comparison_df.to_string(index=False))

best_model_name = comparison_df.iloc[0]['Modelo']
best_r2 = comparison_df.iloc[0]['R¬≤']
best_rmse = comparison_df.iloc[0]['RMSE']

print(f'\nüèÜ MEJOR MODELO: {best_model_name}')
print(f'   R¬≤ = {best_r2:.4f} ({best_r2*100:.1f}%)')
print(f'   RMSE = ${best_rmse:,.2f}')

# Seleccionar el mejor modelo para an√°lisis
if best_model_name == 'Gradient Boosting':
    best_model = gb
    best_predictions = gb_pred
elif best_model_name == 'Random Forest':
    best_model = rf
    best_predictions = rf_pred
else:
    best_model = lr
    best_predictions = lr_pred

# ============================================================================
# 7. FEATURE IMPORTANCE
# ============================================================================

print('\n' + '='*80)
print('üîç FEATURE IMPORTANCE (del mejor modelo)')
print('='*80)

if hasattr(best_model, 'feature_importances_'):
    feat_imp = pd.DataFrame({
        'Feature': features_v2,
        'Importance': best_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print('\nTop 20 Features m√°s importantes:')
    print(feat_imp.head(20).to_string(index=False))
    
    # Guardar feature importance
    feat_imp.to_csv('feature_importance_v2.csv', index=False)
    print('\n‚úì Feature importance guardado en: feature_importance_v2.csv')

# ============================================================================
# 8. VISUALIZACIONES
# ============================================================================

print('\n' + '='*80)
print('üìä GENERANDO VISUALIZACIONES')
print('='*80)

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle(f'üöÄ An√°lisis del Modelo Mejorado - {best_model_name}', 
             fontsize=18, fontweight='bold')

# 1. Real vs Predicci√≥n
axes[0, 0].scatter(y_test, best_predictions, alpha=0.5, s=30, color='#2E86AB')
axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                'r--', lw=2, label='Predicci√≥n perfecta')
axes[0, 0].set_xlabel('Ventas Reales ($)', fontweight='bold', fontsize=12)
axes[0, 0].set_ylabel('Ventas Predichas ($)', fontweight='bold', fontsize=12)
axes[0, 0].set_title(f'Real vs Predicci√≥n (R¬≤ = {best_r2:.4f})', 
                     fontweight='bold', fontsize=13)
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 2. Distribuci√≥n de errores
errors = best_predictions - y_test
axes[0, 1].hist(errors, bins=50, color='#6A4C93', alpha=0.7, edgecolor='black')
axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Error = 0')
axes[0, 1].axvline(errors.mean(), color='green', linestyle='--', linewidth=2, 
                   label=f'Media = ${errors.mean():.2f}')
axes[0, 1].set_xlabel('Error de Predicci√≥n ($)', fontweight='bold', fontsize=12)
axes[0, 1].set_ylabel('Frecuencia', fontweight='bold', fontsize=12)
axes[0, 1].set_title(f'Distribuci√≥n de Errores (RMSE = ${best_rmse:.2f})', 
                     fontweight='bold', fontsize=13)
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# 3. Comparaci√≥n de modelos
model_names = comparison_df['Modelo'].values
r2_scores = comparison_df['R¬≤'].values
colors = ['#51CF66' if r2 > 0.8 else '#FFD93D' if r2 > 0.5 else '#FF6B6B' 
          for r2 in r2_scores]

bars = axes[1, 0].bar(model_names, r2_scores, color=colors, 
                      edgecolor='black', linewidth=2)
axes[1, 0].set_ylabel('R¬≤ Score', fontweight='bold', fontsize=12)
axes[1, 0].set_title('Comparaci√≥n de Modelos', fontweight='bold', fontsize=13)
axes[1, 0].set_ylim([0, 1])
axes[1, 0].axhline(y=0.8, color='green', linestyle='--', alpha=0.5, 
                   label='Excelente (>0.8)')
axes[1, 0].axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, 
                   label='Aceptable (>0.5)')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3, axis='y')

for bar, score in zip(bars, r2_scores):
    height = bar.get_height()
    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,
                    f'{score:.3f}', ha='center', va='bottom', 
                    fontweight='bold', fontsize=12)

# 4. Top 10 Feature Importance
if hasattr(best_model, 'feature_importances_'):
    top_10_feat = feat_imp.head(10)
    feat_names = [f.replace('_enc', '').replace('_', ' ') for f in top_10_feat['Feature']]
    
    y_pos = np.arange(len(feat_names))
    axes[1, 1].barh(y_pos, top_10_feat['Importance'].values, 
                    color=plt.cm.viridis(np.linspace(0.3, 0.9, 10)))
    axes[1, 1].set_yticks(y_pos)
    axes[1, 1].set_yticklabels(feat_names, fontsize=10)
    axes[1, 1].invert_yaxis()
    axes[1, 1].set_xlabel('Importancia', fontweight='bold', fontsize=12)
    axes[1, 1].set_title('Top 10 Features M√°s Importantes', 
                         fontweight='bold', fontsize=13)
    
    for i, v in enumerate(top_10_feat['Importance'].values):
        axes[1, 1].text(v, i, f' {v:.4f}', va='center', fontsize=9)

plt.tight_layout()
plt.savefig('modelo_mejorado_v2_resultados.png', dpi=300, bbox_inches='tight')
print('‚úì Visualizaci√≥n guardada: modelo_mejorado_v2_resultados.png')

# ============================================================================
# 9. AN√ÅLISIS DETALLADO DE ERRORES
# ============================================================================

print('\n' + '='*80)
print('üî¨ AN√ÅLISIS DETALLADO DE ERRORES')
print('='*80)

error_analysis = pd.DataFrame({
    'Real': y_test,
    'Prediccion': best_predictions,
    'Error_Absoluto': np.abs(errors),
    'Error_Porcentual': np.abs(errors / y_test) * 100
})

print('\nEstad√≠sticas de error:')
print(f'  Error promedio: ${errors.mean():.2f}')
print(f'  Error mediano: ${np.median(errors):.2f}')
print(f'  MAE: ${error_analysis["Error_Absoluto"].mean():.2f}')
print(f'  Error % promedio: {error_analysis["Error_Porcentual"].mean():.2f}%')

# Predicciones dentro de rangos
within_10 = (error_analysis['Error_Porcentual'] <= 10).mean() * 100
within_20 = (error_analysis['Error_Porcentual'] <= 20).mean() * 100
within_30 = (error_analysis['Error_Porcentual'] <= 30).mean() * 100

print('\nPredicciones dentro de margen de error:')
print(f'  ¬±10%: {within_10:.1f}% de predicciones')
print(f'  ¬±20%: {within_20:.1f}% de predicciones')
print(f'  ¬±30%: {within_30:.1f}% de predicciones')

# ============================================================================
# 10. COMPARACI√ìN: MODELO ORIGINAL VS MEJORADO
# ============================================================================

print('\n' + '='*80)
print('üìà COMPARACI√ìN: MODELO ORIGINAL VS MEJORADO')
print('='*80)

# Modelo original (del c√≥digo base)
original_r2 = 0.1059
original_rmse = 773.07

improvement_r2 = ((best_r2 - original_r2) / original_r2) * 100
improvement_rmse = ((original_rmse - best_rmse) / original_rmse) * 100

print(f'\nMODELO ORIGINAL (V1):')
print(f'  R¬≤:   {original_r2:.4f} ({original_r2*100:.1f}%)')
print(f'  RMSE: ${original_rmse:,.2f}')
print(f'  Features: 9')

print(f'\nMODELO MEJORADO (V2):')
print(f'  R¬≤:   {best_r2:.4f} ({best_r2*100:.1f}%)')
print(f'  RMSE: ${best_rmse:,.2f}')
print(f'  Features: {len(features_v2)}')

print(f'\nMEJORA:')
print(f'  R¬≤:   {improvement_r2:+.1f}% de mejora')
print(f'  RMSE: {improvement_rmse:+.1f}% de reducci√≥n de error')

# ============================================================================
# 11. GUARDAR RESULTADOS
# ============================================================================

print('\n' + '='*80)
print('üíæ GUARDANDO RESULTADOS')
print('='*80)

# Guardar dataset con predicciones
results_df = df_enhanced.copy()
results_df['Predicted_Sales'] = best_model.predict(X.fillna(0))
results_df['Prediction_Error'] = results_df['Sales'] - results_df['Predicted_Sales']
results_df['Error_Percentage'] = np.abs(results_df['Prediction_Error'] / results_df['Sales']) * 100

results_df.to_csv('superstore_con_predicciones_v2.csv', index=False)
print('‚úì Dataset con predicciones: superstore_con_predicciones_v2.csv')

# Guardar comparaci√≥n de modelos
comparison_df.to_csv('comparacion_modelos_v2.csv', index=False)
print('‚úì Comparaci√≥n de modelos: comparacion_modelos_v2.csv')

# Guardar resumen
with open('resumen_modelo_v2.txt', 'w', encoding='utf-8') as f:
    f.write('='*80 + '\n')
    f.write('RESUMEN - MODELO MEJORADO V2\n')
    f.write('='*80 + '\n\n')
    f.write(f'MEJOR MODELO: {best_model_name}\n')
    f.write(f'R¬≤: {best_r2:.4f} ({best_r2*100:.1f}%)\n')
    f.write(f'RMSE: ${best_rmse:,.2f}\n')
    f.write(f'MAE: ${comparison_df.iloc[0]["MAE"]:,.2f}\n')
    f.write(f'Features utilizadas: {len(features_v2)}\n\n')
    f.write('MEJORA VS MODELO ORIGINAL:\n')
    f.write(f'  R¬≤ V1:   {original_r2:.4f} ‚Üí V2: {best_r2:.4f} ({improvement_r2:+.1f}%)\n')
    f.write(f'  RMSE V1: ${original_rmse:.2f} ‚Üí V2: ${best_rmse:.2f} ({improvement_rmse:+.1f}%)\n\n')
    f.write('TOP 10 FEATURES:\n')
    if hasattr(best_model, 'feature_importances_'):
        for i, row in feat_imp.head(10).iterrows():
            f.write(f'  {row["Feature"]:30s} {row["Importance"]:.4f}\n')

print('‚úì Resumen: resumen_modelo_v2.txt')

print('\n' + '='*80)
print('‚úÖ PROCESO COMPLETADO')
print('='*80)
print(f'\nüéâ ¬°Modelo mejorado exitosamente!')
print(f'   R¬≤ mejorado de 11% a {best_r2*100:.1f}%')
print(f'   Error reducido en {improvement_rmse:.1f}%')
print(f'\nüìÅ Archivos generados:')
print(f'   1. modelo_mejorado_v2_resultados.png')
print(f'   2. superstore_con_predicciones_v2.csv')
print(f'   3. feature_importance_v2.csv')
print(f'   4. comparacion_modelos_v2.csv')
print(f'   5. resumen_modelo_v2.txt')
print('\n' + '='*80)